{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "all_data = np.concatenate((x_train, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_datasets(nums, datas, labels, nclasses=10):\n",
    "    shape_data = list(datas.shape)\n",
    "    shape_data[0] = nums\n",
    "    shape_data = tuple(shape_data)\n",
    "    shape_label = list(labels.shape)\n",
    "    shape_label[0] = nums\n",
    "    shape_label = tuple(shape_label)\n",
    "    data = np.zeros(shape_data)\n",
    "    label = np.zeros(shape_label)\n",
    "    cls_num = dict(zip(range(0, nclasses), [0]*nclasses))\n",
    "    datas, labels = shuffle(datas, labels)\n",
    "    \n",
    "    num_total = 0\n",
    "    for i in range(datas.shape[0]):\n",
    "        if num_total >= nums:\n",
    "            break\n",
    "        num_class = cls_num[labels[i][0]] \n",
    "        #print(labels[i][0], num_class)\n",
    "        if num_class < (nums/nclasses):\n",
    "            data[num_total] = datas[i]\n",
    "            label[num_total] = labels[i]\n",
    "            num_total += 1\n",
    "            cls_num[labels[i][0]]  += 1\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_5000_training_data():\n",
    "    return get_random_datasets(5000,x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_1000_test_data():\n",
    "    return get_random_datasets(1000,x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(datasets):\n",
    "    #normalize to mean 0 std 1\n",
    "    gen = ImageDataGenerator(featurewise_center=True,featurewise_std_normalization=True) \n",
    "    gen.fit(all_data)\n",
    "    datasets_norm = (datasets - gen.mean)/gen.std\n",
    "    #rescale to 224*224\n",
    "    datasets_resized = np.zeros((datasets.shape[0], 224, 224,3))\n",
    "    for i in range(len(datasets)):\n",
    "        datasets_resized[i] =  cv2.resize(datasets_norm[i], (224,224))\n",
    "    return datasets_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_inputs_and_labels(datasets, labels):\n",
    "    #get 2 inputs and corresponding label of the inputs. If the 2 are same class , label is 1. otherwise is 0.\n",
    "    pair_datasets = np.zeros_like(datasets)\n",
    "    new_labels = np.zeros_like(labels)\n",
    "    for i in range(len(datasets)-1):\n",
    "        pair_datasets[i] = datasets[i+1]\n",
    "        if labels[i] == labels[i+1]:\n",
    "            new_labels[i] = [1]\n",
    "    pair_datasets[len(datasets)-1] = datasets[0]\n",
    "    if labels[len(datasets)-1] == labels[0]:\n",
    "        new_labels[len(datasets)-1] = [1]\n",
    "    return datasets, pair_datasets, new_labels\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_input_and_labels(train = True):\n",
    "    if train:\n",
    "        ori_data, ori_label = get_5000_training_data()\n",
    "    else:\n",
    "        ori_data, ori_label = get_1000_test_data()\n",
    "        \n",
    "    return preprocess_data(ori_data), to_categorical(ori_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
